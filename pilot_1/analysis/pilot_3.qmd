---
title: "Pilot 3 Data Wrangling"
format: html
bibliography: mocareferences.bib
citation-location: document
reference-location: section
editor: visual
---

## Abstract

In an era of rising polarization, Americans face increasing challenges when engaging in respectful conversations across ideological divides (Klein, 2020). While human-to-human conversations have been shown to increase empathy and reduce polarization (e.g., Broockman & Kalla, 2016, Combs et al., 2023, and Elnakouri et al., 2024), they are often difficult to initiate and sustain, particularly in socially or politically charged environments. As existing research has found that large language models (LLMs) can impact user beliefs (e.g., Chalaguine et al., 2019 & Costello et al., 2024), this study investigates whether LLMs can serve as accessible tools to support and encourage more open-minded human-to-human conversations. Drawing on prior research into conversational styles that promote civility and perspective-taking, we developed a specialized chatbot using ChatGPT and tested it in this experiment. American participants discussed one of seven controversial topics with the chatbot and completed surveys before and after the conversation to assess changes in willingness to engage, open-mindedness, and belief extremity. Results suggest that certain chatbot styles may positively influence users’ attitudes in ways that support productive future dialogue. This research positions LLMs as scalable, private, and low-risk tools that can help prepare individuals for more thoughtful engagement with those they disagree with. Applications could revolutionize educational settings and online platforms, where dissenting views often face social penalties. Future research should administer the chatbot intervention and then assess changes in key measures by having subjects participate in a human-to-human conversation . 

```{r}
#| label: Data Fetching. Load R packages
#| include: false 

library(osfr)
library(ez)
library(tidyverse)
library(gt)
library(gtsummary)
library(kableExtra)
library(stringr)
library(ggridges)
library(DiagrammeR) # for flowchart 
# library(knitr)
# library(corrplot)
# library(GGally)
# library(car)
# library(MASS)
# library(glmnet)

```

```{r}
#| label: Prolific demographics data
#| include: false 

## add which round of the pilot it was by reading in demographics files so we know completion dates

#read in prolific demographics files 
demo1 <- read_csv("prolific_export_66a7f5efd46ad7a2b78cc200.csv") %>%
  mutate(Age = as.numeric(Age))

#merge files (if multiple)
full_prolific_demographics_df <- bind_rows(demo1) 

#clean df
full_prolific_demographics_df <- full_prolific_demographics_df %>%
# make name the same as in data csvs so merging is easier
rename("prolific_subject_id" = "Participant id") %>%
# filter out people who didn't finish
filter(Status != "RETURNED") %>%
#rename "Started at" to make grepl function easier to use later on
rename("start" = "Started at") %>%
# make time more readable but keep the seconds version for analysis stuff later
mutate(`Time taken (minutes)` = as.numeric(`Time taken`) / 60) %>%
# manually remove one subject who didn't receive a condition because i messed up our experiment code and one subject who didn't give us their data
  filter(prolific_subject_id != "65fc207aef1f5877493fe5e8") %>% 
  filter(prolific_subject_id != "6602ce6267191d285a324221") %>% 
# name the round of the pilot that the person was in 
  mutate(pilot_iteration = case_when(
    grepl("2024-08-02", start) ~ "2.1 (Combo, selection, control)",
    TRUE ~ NA_character_
  )) 
```

```{r}
#| label: Retrieve data from our OSF project. Loading into a data folder, which  we manually create
#| include: false 

osf_retrieve_node("x32pv") %>%
   osf_ls_files(
     n_max = 100000000000000000000000000000000000000000000000000
   ) %>%
   osf_download(path = "data", conflicts = "skip")

```

```{r}
#| label: Bind csv's
#| include: false 

osf_csv_filenames <- list.files(path = "data/")
raw_dfs_tibbles <- map(osf_csv_filenames, ~read_csv(file.path("data/", .)))
rawwwwwww_df <- bind_rows(raw_dfs_tibbles)

```

```{r}
#| label: Merge prolific demos + create a condition type column
#| include: false 

raw_df <- rawwwwwww_df %>%
  # inner join with the demographics df from pilot 2 so we can eliminate pilot 1 subjects
  inner_join(full_prolific_demographics_df, by = "prolific_subject_id") %>%
  # manually remove one subject who didn't receive a condition because i messed up our experiment code and one subject who didn't give us their data
  filter(prolific_subject_id != "65fc207aef1f5877493fe5e8") %>% 
  filter(prolific_subject_id != "6602ce6267191d285a324221") %>%
  # add condition column
  mutate(condition = case_when(
     grepl("Additionally, you are being fed three potential responses to this user's message.", logs) ~ "selection bot",
    TRUE ~ NA_character_
  )) %>%
  mutate(condition = case_when(
    grepl("Task 2: Very briefly summarize the arguments", logs) ~ "combination bot",
    phase == "control-intervention" ~ "control free reflection",
    TRUE ~ condition
  )) %>%
  # remove unnecessary syntax from rowAsString and topicChoiceAsString for readability later
  mutate(rowAsString = gsub('\\{"row":"', '', rowAsString)) %>%
  mutate(rowAsString = gsub('"}', '', rowAsString)) %>%
  mutate(topicChoiceAsString = gsub('\\{"row":"', '', topicChoiceAsString)) %>%
  mutate(topicChoiceAsString = gsub('"}', '', topicChoiceAsString)) %>%
  # fill condition column and row and topic strings
  group_by(prolific_subject_id) %>%
  fill(condition, .direction = "downup") %>%
  fill(rowAsString, .direction = "downup") %>%
  fill(topicChoiceAsString, .direction = "downup") %>%
  ungroup() 

# number of subjects in data 
total_num_subjects_in_data <- nrow(raw_df %>%
  group_by(prolific_subject_id) %>%
  summarize(total_num_subjects_in_data = n()))

```

```{r}
#| label: Experimenting with a new way of coding Surveys data frame
#| include: false

surveys_cleaning_df <- raw_df %>%
  # Filter for only surveys
  filter(trial_type == "survey") %>%
  # Remove control interventions (these are coded as surveys)
  filter(phase != "control-intervention") %>%
  # Remove the matrix question titles because they mess with separating questions from answers
  # republican/democrat (pre-convo)
  mutate(across(everything(), ~ gsub(',"rating-republicans":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub(',"rating-democrats":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"rating-republicans":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"rating-democrats":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"interacting-with-republicans":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"interacting-with-democrats":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"interacting-with-republicans":null', '', .))) %>%
  mutate(across(everything(), ~ gsub('"interacting-with-democrats":null', '', .))) %>%
  mutate(across(everything(), ~ gsub('"rating-republicans":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"rating-democrats":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"interacting-with-republicans":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"interacting-with-democrats":', '', .))) %>%
  # republican/democrat (post-convo)
  mutate(across(everything(), ~ gsub('"rating-republicans-post":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"rating-democrats-post":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"interacting-with-republicans-post":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"interacting-with-democrats-post":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"rating-republicans-post":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"rating-democrats-post":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"interacting-with-republicans-post":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"interacting-with-democrats-post":', '', .))) %>%
  #topic-specific polarization (pre-convo)
  mutate(across(everything(), ~ gsub('"euthanasia-polarization":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"gender-polarization":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"healthcare-polarization":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"bombing-polarization":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"vaccines-polarization":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"criminal-polarization":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"same-sex-polarization":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"euthanasia-polarization":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"gender-polarization":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"healthcare-polarization":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"bombing-polarization":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"vaccines-polarization":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"criminal-polarization":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"same-sex-polarization":', '', .))) %>%
  #topic-specific polarization (post-convo)
  mutate(across(everything(), ~ gsub('"euthanasia-polarization-post":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"gender-polarization-post":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"healthcare-polarization-post":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"bombing-polarization-post":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"vaccines-polarization-post":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"criminal-polarization-post":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"same-sex-polarization-post":null,', '', .))) %>%
  mutate(across(everything(), ~ gsub('"euthanasia-polarization-post":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"gender-polarization-post":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"healthcare-polarization-post":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"bombing-polarization-post":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"vaccines-polarization-post":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"criminal-polarization-post":', '', .))) %>%
  mutate(across(everything(), ~ gsub('"same-sex-polarization-post":', '', .))) %>%
  # the name of the question in 2.1 run of the experiment
  mutate(across(everything(), ~ gsub('topicChoice":', '', .))) %>%
  # the name of the question in future runs of the experiment
  mutate(across(everything(), ~ gsub('topic":', '', .))) %>%
  mutate(across(everything(), ~ gsub(',null,', '', .))) 

  
ssurveys_df <- ssurveys_cleaning_df %>%
  # Remove weird characters but don't remove quotations because we need them for separating questions
  mutate(across(everything(), ~ gsub('}', '', .))) %>%
  mutate(across(everything(), ~ gsub('\\{', '', .))) %>%
  mutate(across(everything(), ~ gsub('\\[', '', .))) %>%
  mutate(across(everything(), ~ gsub('\\]', '', .))) %>%
  # Make each question its own row
  separate_rows(response, sep = ',"') %>%
  # Remove any leftover quotation marks
  mutate(across(everything(), ~ gsub('"', '', .))) %>%
  # Move answers to a new column
  separate(response, into = c("question", "answer"), sep = ":", extra = "merge", fill = "right") %>%
  # Remove all remaining questions that were answered with null (like the slider questions, because the slider 'placeholder' questions are where people actually answer the slider questions)
  filter(!is.na(answer) & answer != 'null' & answer != 'null,null') %>%
  # Remove the gender polarization line that we currently don't know how to code 
  filter(!grepl("Gender should be disregarded when selecting candidates for career advancement opportunities", question)) %>%
  # Bin the religious affiliations because they were free response 
   mutate(answer = case_when(
    question == "religious-affiliation" & str_detect(str_to_lower(answer), "christian") ~ "Christian/Catholic",
    question == "religious-affiliation" & str_detect(str_to_lower(answer), "catholic") ~ "Christian/Catholic",
    question == "religious-affiliation" & str_detect(str_to_lower(answer), "atheis|none|") ~ "Atheist/None",
    question == "religious-affiliation" & str_detect(str_to_lower(answer), "Nothing in Particular") ~ "Atheist/None",
    TRUE ~ answer
  )) 

```

```{r}
#| label: Created automated process for flagging transcripts that might have been pasted in
#| include: false

# flag copy pastes
copypaste_flagging <- raw_df %>%
  #filter for conversations again
  filter(trial_type == "chat") %>%
  select(prolific_subject_id, logs, condition) %>%
  separate_rows(logs, sep = '"role":"user","content":"') %>%
  separate_rows(logs, sep = 'keyPressLog') %>%
  #remove the excess content in each entry that comes after the keypresslog
    # for combo bot
   mutate(logs = gsub('"role":"assistant","content".*', '', logs)) %>%
    # for selection bot 
  mutate(logs = gsub('"role":"selection_prompt","content".*', '', logs)) %>%
  #remove rows that start with (0) because that means that the "role" "user" "content" was within the selection bot's prompt
  filter(!grepl('(0)', logs)) %>%
  #remove rows that aren't keypress logs
  filter(!grepl('^\\[\\{"role":"system","content":', logs)) %>%
  #remove some excess punctuation
  mutate(logs = gsub('":\\[', '', logs)) %>%
  mutate(logs = gsub('\\]\\},\\{', '', logs)) %>%
  #create new column to identify copy paste
  group_by(prolific_subject_id) %>%
  mutate(flag = case_when(
    grepl('"Command","v"', logs) | grepl('"Control","v"', logs)  ~ "copy-pasted",
    TRUE ~ NA_character_
  )) %>%
  ungroup()

# extract value for text 
failed_copypaste_check <- copypaste_flagging %>%
  filter(flag == 'copy-pasted') %>%
  summarize(failed_copypaste_check = n_distinct(prolific_subject_id)) %>%
  pull(failed_copypaste_check)

# get their ids so we can remove them from data analysis
failed_copypaste_check_subject_ids <- copypaste_flagging %>%
  filter(flag == 'copy-pasted') %>%
  distinct(prolific_subject_id) %>%
  pull(prolific_subject_id)

# look at number of individual key presses and number of characters in responses. anytime response is longer than keypresses should be flagged 
character_count_flagging <- raw_df %>%
  #filter for conversations again
  filter(trial_type == "chat") %>%
  filter(prolific_subject_id != "60d6befca58e40d0c63bba9f") %>%
  filter(prolific_subject_id != "669f491562bcbc5facd5014b") %>%
  select(prolific_subject_id, logs, condition) %>%
  #separate based on keypress log
  separate_rows(logs, sep = 'keyPressLog') %>%
  mutate(logs = gsub('"role":"assistant","content".*\\}\\],"time"', '', logs)) %>%
  mutate(logs = gsub('\\]\\},\\{"role":"selection_prompt","content".*\\}\\],"time"', '', logs)) %>%
  separate_rows(logs, sep = '"role":"user","content":"') %>%
  #remove rows that don't contain user messages 
  filter(!grepl('^\\[\\{"role":"system","content":', logs)) %>%
  # remove excess syntax at end of keypress 
  mutate(logs = gsub('"\\]\\},\\{.*', '', logs)) %>%
  mutate(logs = gsub('":\\[', '', logs)) %>%
  mutate(logs = gsub('","time":.*', '', logs)) %>%
  # turn keypress log into its own column so we can compare character counts easier
  mutate(row_group = rep(1:(n()/2), each = 2))  %>%
  group_by(row_group) %>%
  mutate(message_log = lag(logs)) %>%
  ungroup() %>%
  filter(!is.na(message_log)) %>%
  rename(keypress_log = logs) %>%
  select(-row_group)

#count the number of characters, which are separated by quotation marks (counting keys like Backspace, Shift, etc. as one character. can remove them from df first if we want more precision)
character_count_flagging$keypress_character_count <- str_count(character_count_flagging$keypress_log, '"')/2 - 0.5

#count message number of characters
character_count_flagging$message_character_count <- nchar(character_count_flagging$message_log)

# flag fishy cases
character_count_flagging <- character_count_flagging %>%
  mutate(flag = case_when(
    keypress_character_count < message_character_count ~ "fishy",
    TRUE ~ NA_character_
  ))

# get count of how many ppl are fishy
failed_character_count_check <- character_count_flagging %>%
  filter(flag == 'fishy') %>%
 summarize(failed_character_count_check = n_distinct(prolific_subject_id)) %>%
pull(failed_character_count_check)

# get their ids so we can remove them from data analysis
failed_character_count_subject_ids <- character_count_flagging %>%
  filter(flag == 'fishy') %>%
  distinct(prolific_subject_id) %>%
  pull(prolific_subject_id)
```

```{r}
#| label: Create a df that flags people who failed the attention check
#| include: false

attention_check <- surveys_df %>%
  filter(question == "attention-check-slider-post-placeholder" | question == "attention-check-slider-pre-placeholder") %>%
  group_by(prolific_subject_id) %>%
  mutate(flag = case_when(
    sum(answer == "0.00") == 0 ~ "double fail", #double fail means we should reject their data
    sum(answer == "0.00") == 1 ~ "single fail", #single fail is not means for rejecting data
    sum(answer == "0.00") == 2 ~ "pass", #good subject :3
    TRUE ~ NA_character_
  )) %>%
  ungroup() %>%
  select(flag, question, answer, prolific_subject_id, "Time taken (minutes)", condition) %>%
  # REMOVE THIS FOR FULL EXPERIMENT, manually making one subject pass because i had an error in the experiment code that made the subject not receive one of the attention checks (nothing else was affected in their data)
  mutate(flag = if_else(prolific_subject_id == "66ac39dd781146c974c07009", "pass", flag))

# extract value for text 
total_failed_attention_checks <- attention_check %>%
  # excluding people for both fails
  filter(flag == 'double fail' | flag == 'single fail') %>%
  # add distinct because there are two attention check questions so a failed subject gets flagged twice
  summarize(total_failed_attention_checks = n_distinct(prolific_subject_id)) %>%
  pull(total_failed_attention_checks)

# get count of how many ppl double failed
failed_attention_checks_subject_ids <- attention_check %>%
  filter(flag == 'double fail') %>%
  distinct(prolific_subject_id) %>%
  pull(prolific_subject_id)

```

```{r}
#| label: Remove bad subs
#| include: false

# remove bad subs
raw_df <- raw_df %>%
  filter(!(prolific_subject_id %in% failed_copypaste_check_subject_ids)) %>%
  filter(!(prolific_subject_id %in% failed_character_count_subject_ids)) %>%
  filter(!(prolific_subject_id %in% total_failed_attention_checks))
    
surveys_df <- surveys_df %>%
  filter(!prolific_subject_id %in% failed_copypaste_check_subject_ids)  %>%
  filter(!prolific_subject_id %in% failed_character_count_subject_ids)  %>%
  filter(!prolific_subject_id %in% failed_attention_checks_subject_ids) 
  
total_num_clean_subjects_in_data <- nrow(raw_df %>%
  group_by(prolific_subject_id) %>%
  summarize(total_num_clean_subjects_in_data = n()))

```

## Introduction

Americans are increasingly unwilling to engage in conversations about emotionally charged or politically divisive topics—discussions that are essential for fostering empathy, intellectual humility, and democratic resilience (@finkel2020; @iyengar2019). While human-to-human conversations have been shown to increase open-mindedness and reduce polarization (e.g., @broockman2016; @combs2023; @elnakouri2024; @fernbach2013), these same conversations can also become unproductive and inaccessible, leaving participants even more reluctant to engage in future dialogue (cite). This growing reluctance presents a societal challenge: how can we foster greater willingness in Americans to engage with each other across ideological divides?

Recent findings suggest that artificial intelligence (AI), particularly conversational large language models (LLMs), can promote open-mindedness and persuade users. Research has shown that AI can shift user beliefs, increase receptiveness to opposing views, and encourage intellectual humility (@altay2022; @chalaguine2019; @costello2024; @matz2024). While these characteristics are thought to be closely linked with willingness to converse (cite), research has not directly tested whether conversations with a conversational LLM can increase willingness to converse about divisive topics in the U.S..

We propose that conversational large language models (LLMs) could serve as a low-stakes, scalable, and emotionally neutral entry point into difficult dialogues—one that increases users' willingness to engage in productive, open-minded conversations. To explore this, we developed the Mind-Opening Conversational Agent (MOCA), a response-election chatbot system designed specifically to increase users’ willingness to engage in discussions about polarizing issues. 

MOCA is comprised of four chatbots that generate potential responses and a fifth chatbot that selects and outputs the response that it deems most likely to increase willingness to converse (Figure 1). We based three of the four response-generating chatbots' approaches on findings in the human-to-human research (e.g., @broockman2016; @combs2023; @elnakouri2024; @fernbach2013), but left the fourth approach as minimal as possible to increase MOCA's autonomy. In this way, there are two avenues through which MOCA could influence users: through literature-backed, prompt-engineered approaches and through MOCA's own approach.

```{r}
#| label: flowchart-selection-bot
#| echo: false
#| tbl-cap: Graphic of selection bot process.

grViz("
digraph chatbot_flow {
  
  graph [layout = dot, rankdir = LR]

  node [shape = note, style = filled, fillcolor = lightblue]

  user_input [label = 'User\\nmessage\\ninput']
  counter_response [label = 'Bot generates\\ncounter-argument\\nresponse', shape = box]
  question_response [label = 'Bot generates\\nquestion\\nresponse', shape = box]
  viewpoint_response [label = 'Bot generates\\nviewpoint\\nresponse', shape = box]
  bot_decision [label = 'Bot chooses\\nbest\\nresponse', shape = circle, width=1.2]
  final_output [label = 'Bot\\nmessage\\noutput']

  user_input -> counter_response
  user_input -> question_response
  user_input -> viewpoint_response

  counter_response -> bot_decision
  question_response -> bot_decision
  viewpoint_response -> bot_decision

  bot_decision -> final_output
}
")
```

We worked with six divisive topics in the U.S. during the development of our chatbot approaches and will have users select one of these for their conversation: human euthanasia, the role of the government in healthcare, same-sex marriage, mandating vaccines, the criminal justice system, and gender equality. To evaluate MOCA’s effectiveness, we will administer pre- and post-intervention surveys assessing open-mindedness, polarization, and willingness to converse. If MOCA is effective, we expect to observe increased open-mindedness and willingness to converse, alongside reduced polarization, when comparing pre- and post-intervention survey responses. By adapting techniques shown to be effective in human-human conversations to a modern AI framework, we aim to evaluate whether LLMs can serve as scalable tools for encouraging open dialogue on contentious issues.


## Methods

### Participants

We pre-registered a target sample size of `r total_num_subjects_in_data` participants to achieve sufficient statistical power. We restricted our study to Prolific users who fluently speak English, currently reside in the United States, and reported the United States as their nationality and country of birth. Per Prolific's harmful content criteria, we also restricted our study to participants who have consented to participating in studies with harmful content. This study was approved by the Vassar College Institutional Review Board. After applying exclusion criteria, `r total_num_clean_subjects_in_data` subjects remain. We excluded `r total_failed_attention_checks` subjects for failing one or more of the attention checks in the surveys and `r failed_copypaste_check + failed_character_count_check` subjects for likely plagiarizing their conversation messages.

```{r}
#| label: Reverse code for quantitative analysis
#| include: false

reverse_coded_scores_df <- surveys_df %>%
   # In the experiment code, we put '@R@' in all statements that are supposed to be reverse coded. So we can grab all of those statements here and reverse them. The only statements that don't have @R@ are the pre-convo survey polarization statements because those were converted into strings for the chatbot to use
   mutate(answer = ifelse(
         grepl("@R@", question) | 
         grepl("It is not right for family members to request euthanasia on behalf of incapacitated patients", question) | 
         grepl("Euthanasia should be banned for patients with non-terminal conditions", question) |
         grepl("Euthanasia should be banned for all patients", question) |
         grepl("Euthanasia should not be performed at home", question) |
         grepl("The competitive market should drive healthcare prices", question) |
        grepl("Policies that take gender into account often do more harm than good in achieving gender equality", question) | 
          grepl("Gender should be disregarded when selecting candidates for career advancement opportunities to ensure that selections are based on merit", question) | 
          grepl("Policies aimed at reducing inequality for women often create unfair advantages for women over men", question) |
         grepl("The bombings were justified to bring a swift end to the war", question) |
         grepl("Preventing people without vaccinations from entering public spaces and transportation would do more harm than good", question)  |
         grepl("Businesses and institutions should be barred from discriminating based on vaccination status", question) |
         grepl("It is not right to provide the same federal rights and support for same-sex couples as opposite-sex couples", question),
     7 - as.numeric(answer),
     answer
   )) 

sliders_df <- reverse_coded_scores_df %>%
filter(grepl("slider", question))

#change to be based around 0
reverse_coded_mean_zero_scores_df <- reverse_coded_scores_df %>%
filter(!grepl("slider", question)) %>%
  mutate(answer = recode(as.numeric(answer),
                         `7` = 3,
                         `6` = 2,
                         `5` = 1,
                         `4` = 0,
                         `3` = -1,
                         `2` = -2,
                         `1` = -3,
                         .default = as.numeric(answer)
  ))
```

```{r}
#| label: Get pre- and post-intervention mean scores for polarization questions (specific and general lumped together)
#| include: false

pre_polarization_df <- reverse_coded_scores_df %>%
  group_by(prolific_subject_id) %>%
  filter(grepl("Euthanasia should be allowed for terminally ill patients who request it", question) |
           grepl("Legal protections should be provided for doctors who perform euthanasia", question) | 
           grepl("It is not right for family members to request euthanasia on behalf of incapacitated patients", question) | 
           grepl("Euthanasia should only be allowed if the patient has received a psychological evaluation", question) |
           grepl("Euthanasia should be banned for patients with non-terminal conditions", question) |
           grepl("Euthanasia should be banned for all patients", question) |
           grepl("Euthanasia should not be performed at home", question) |
           grepl("Gender quotas should be implemented in corporate boards and executive positions", question)  |
         grepl("Mandating equal pay for equal work regardless of gender would improve gender equality", question) |
         grepl("Both mothers and fathers should be provided with parental leave", question) |
         grepl("Free childcare services should be provided to support working parents", question) |
         grepl("Funding for programs aimed at reducing gender-based violence should be increased", question) |
         grepl("Gender diversity should be encouraged in STEM fields through scholarships and grant", question) |
         grepl("Gender should be disregarded when selecting candidates for career advancement opportunities", question) |
           grepl("A universal healthcare system should be implemented in the U.S.", question)  |
         grepl("Medicaid should be expanded to cover more low-income individuals", question) |
         grepl("Prescription drug prices should be regulated to make them more affordable", question) |
         grepl("Government subsidies should be provided for private health insurance", question) |
         grepl("The government should negotiate drug prices with pharmaceutical companies", question) |
         grepl("Government funding should be increased for mental health services", question) |
         grepl("The competitive market should drive healthcare prices", question)
          | grepl("A memorial should be established in the U.S. to honor the victims of the bombings", question)  |
         grepl("The U.S. government should provide financial reparations to the survivors and their families", question) |
         grepl("The bombings were justified to bring a swift end to the war", question) |
         grepl("The bombings were morally wrong", question) |
         grepl("Learning about the atomic bombings of Hiroshima and Nagasaki is essential for understanding the consequences of nuclear warfare", question) |
         grepl("The U.S. should take responsibility for the humanitarian impact of the bombings", question) |
         grepl("The U.S. should participate in international efforts to promote nuclear disarmament and non-proliferation", question) |
           grepl("Preventing people without vaccinations from entering public spaces and transportation would do more harm than good", question)  |
         grepl("Vaccines should be mandated for healthcare workers", question) |
         grepl("Businesses should be allowed to require proof of vaccination for entry", question) |
         grepl("Businesses and institutions should be barred from discriminating based on vaccination status", question) |
         grepl("Schools should be allowed to require vaccinations for attendance", question) |
         grepl("All government-approved vaccines should be mandated", question)   |
           grepl("Implementing comprehensive background checks for all individuals entering the criminal justice system is necessary", question)  |
         grepl("Enhancing mental health support services for incarcerated individuals would be worth the cost and resources", question) |
         grepl("The use of solitary confinement as a punishment should be banned", question) |
         grepl("Inmates should have greater access to educational programs", question) |
         grepl("Non-violent offenders should be permitted to serve sentences through community service or house arrest", question) |
         grepl("The use of private prisons should be restricted", question) | 
           grepl("Same-sex marriage should remain legalized nationwide", question)  |
         grepl("Adoption rights should be granted to married same-sex couples", question) |
         grepl("Employment non-discrimination protections should be provided for gay and lesbian individuals", question) |
         grepl("Same-sex couples should receive spousal benefits (e.g. health insurance; survivor benefits)", question) |
         grepl("It is not right to provide the same federal rights and support for same-sex couples as opposite-sex couples", question) |
         grepl("Discrimination against same-sex couples in housing and public accommodations should be banned", question) |
          grepl("polarization-general", question)
           ) %>%
  filter(grepl("pre-convo", phase)) %>%
  group_by(prolific_subject_id) %>%
  summarize(
    condition = first(condition),
    total_score = sum(as.numeric(answer), na.rm = TRUE),
    pre_mean_score = mean(as.numeric(answer), na.rm = TRUE),
    min_score = min(as.numeric(answer), na.rm = TRUE),
    max_score = max(as.numeric(answer), na.rm = TRUE)
  )

post_polarization_df <- reverse_coded_scores_df %>%
  group_by(prolific_subject_id) %>%
  filter(grepl("Euthanasia should be allowed for terminally ill patients who request it", question) |
           grepl("Legal protections should be provided for doctors who perform euthanasia", question) | 
           grepl("It is not right for family members to request euthanasia on behalf of incapacitated patients", question) | 
           grepl("Euthanasia should only be allowed if the patient has received a psychological evaluation", question) |
           grepl("Euthanasia should be banned for patients with non-terminal conditions", question) |
           grepl("Euthanasia should be banned for all patients", question) |
           grepl("Euthanasia should not be performed at home", question) |
           grepl("Gender quotas should be implemented in corporate boards and executive positions", question)  |
         grepl("Mandating equal pay for equal work regardless of gender would improve gender equality", question) |
         grepl("Both mothers and fathers should be provided with parental leave", question) |
         grepl("Free childcare services should be provided to support working parents", question) |
         grepl("Funding for programs aimed at reducing gender-based violence should be increased", question) |
         grepl("Gender diversity should be encouraged in STEM fields through scholarships and grant", question) |
         grepl("Gender should be disregarded when selecting candidates for career advancement opportunities", question) |
           grepl("A universal healthcare system should be implemented in the U.S.", question)  |
         grepl("Medicaid should be expanded to cover more low-income individuals", question) |
         grepl("Prescription drug prices should be regulated to make them more affordable", question) |
         grepl("Government subsidies should be provided for private health insurance", question) |
         grepl("The government should negotiate drug prices with pharmaceutical companies", question) |
         grepl("Government funding should be increased for mental health services", question) |
         grepl("The competitive market should drive healthcare prices", question)
          | grepl("A memorial should be established in the U.S. to honor the victims of the bombings", question)  |
         grepl("The U.S. government should provide financial reparations to the survivors and their families", question) |
         grepl("The bombings were justified to bring a swift end to the war", question) |
         grepl("The bombings were morally wrong", question) |
         grepl("Learning about the atomic bombings of Hiroshima and Nagasaki is essential for understanding the consequences of nuclear warfare", question) |
         grepl("The U.S. should take responsibility for the humanitarian impact of the bombings", question) |
         grepl("The U.S. should participate in international efforts to promote nuclear disarmament and non-proliferation", question) |
           grepl("Preventing people without vaccinations from entering public spaces and transportation would do more harm than good", question)  |
         grepl("Vaccines should be mandated for healthcare workers", question) |
         grepl("Businesses should be allowed to require proof of vaccination for entry", question) |
         grepl("Businesses and institutions should be barred from discriminating based on vaccination status", question) |
         grepl("Schools should be allowed to require vaccinations for attendance", question) |
         grepl("All government-approved vaccines should be mandated", question)   |
           grepl("Implementing comprehensive background checks for all individuals entering the criminal justice system is necessary", question)  |
         grepl("Enhancing mental health support services for incarcerated individuals would be worth the cost and resources", question) |
         grepl("The use of solitary confinement as a punishment should be banned", question) |
         grepl("Inmates should have greater access to educational programs", question) |
         grepl("Non-violent offenders should be permitted to serve sentences through community service or house arrest", question) |
         grepl("The use of private prisons should be restricted", question) | 
           grepl("Same-sex marriage should remain legalized nationwide", question)  |
         grepl("Adoption rights should be granted to married same-sex couples", question) |
         grepl("Employment non-discrimination protections should be provided for gay and lesbian individuals", question) |
         grepl("Same-sex couples should receive spousal benefits (e.g. health insurance; survivor benefits)", question) |
         grepl("It is not right to provide the same federal rights and support for same-sex couples as opposite-sex couples", question) |
         grepl("Discrimination against same-sex couples in housing and public accommodations should be banned", question)|
          grepl("polarization-general", question)
           ) %>%
  filter(grepl('post-convo', phase)) %>%
  group_by(prolific_subject_id) %>%
  summarize(
    condition = first(condition),
    total_score = sum(as.numeric(answer), na.rm = TRUE),
    post_mean_score = mean(as.numeric(answer), na.rm = TRUE),
    min_score = min(as.numeric(answer), na.rm = TRUE),
    max_score = max(as.numeric(answer), na.rm = TRUE)
  )
```

```{r}
#| label: Get pre- and post- intervention mean scores for general polarization questions only
#| include: false

pre_polarization_general_df <- reverse_coded_scores_df %>%
   group_by(prolific_subject_id) %>%
  filter(grepl("polarization-general", question))%>%
  filter(grepl('pre-convo', phase)) %>%
  group_by(prolific_subject_id) %>%
  summarize(
    condition = first(condition),
    total_score = sum(as.numeric(answer), na.rm = TRUE),
    pre_mean_score = mean(as.numeric(answer), na.rm = TRUE),
    min_score = min(as.numeric(answer), na.rm = TRUE),
    max_score = max(as.numeric(answer), na.rm = TRUE)
  )


post_polarization_general_df <- reverse_coded_scores_df %>%
   group_by(prolific_subject_id) %>%
  filter(grepl("polarization-general", question)) %>%
  filter(grepl("post-convo", phase)) %>%
  group_by(prolific_subject_id) %>%
  summarize(
    condition = first(condition),
    total_score = sum(as.numeric(answer), na.rm = TRUE),
    post_mean_score = mean(as.numeric(answer), na.rm = TRUE),
    min_score = min(as.numeric(answer), na.rm = TRUE),
    max_score = max(as.numeric(answer), na.rm = TRUE)
  )

```

```{r}
#| label: Get pre- and post-intervention mean scores for specific polarization questions only
#| include: false

pre_specific_polarization_df <- reverse_coded_scores_df %>%
  group_by(prolific_subject_id) %>%
  filter(grepl("Euthanasia should be allowed for terminally ill patients who request it", question) |
           grepl("Legal protections should be provided for doctors who perform euthanasia", question) | 
           grepl("It is not right for family members to request euthanasia on behalf of incapacitated patients", question) | 
           grepl("Euthanasia should only be allowed if the patient has received a psychological evaluation", question) |
           grepl("Euthanasia should be banned for patients with non-terminal conditions", question) |
           grepl("Euthanasia should be banned for all patients", question) |
           grepl("Euthanasia should not be performed at home", question) |
           grepl("Gender quotas should be implemented in corporate boards and executive positions", question)  |
         grepl("Mandating equal pay for equal work regardless of gender would improve gender equality", question) |
         grepl("Both mothers and fathers should be provided with parental leave", question) |
         grepl("Free childcare services should be provided to support working parents", question) |
         grepl("Funding for programs aimed at reducing gender-based violence should be increased", question) |
         grepl("Gender diversity should be encouraged in STEM fields through scholarships and grant", question) |
         grepl("Gender should be disregarded when selecting candidates for career advancement opportunities", question) |
           grepl("A universal healthcare system should be implemented in the U.S.", question)  |
         grepl("Medicaid should be expanded to cover more low-income individuals", question) |
         grepl("Prescription drug prices should be regulated to make them more affordable", question) |
         grepl("Government subsidies should be provided for private health insurance", question) |
         grepl("The government should negotiate drug prices with pharmaceutical companies", question) |
         grepl("Government funding should be increased for mental health services", question) |
         grepl("The competitive market should drive healthcare prices", question)
          | grepl("A memorial should be established in the U.S. to honor the victims of the bombings", question)  |
         grepl("The U.S. government should provide financial reparations to the survivors and their families", question) |
         grepl("The bombings were justified to bring a swift end to the war", question) |
         grepl("The bombings were morally wrong", question) |
         grepl("Learning about the atomic bombings of Hiroshima and Nagasaki is essential for understanding the consequences of nuclear warfare", question) |
         grepl("The U.S. should take responsibility for the humanitarian impact of the bombings", question) |
         grepl("The U.S. should participate in international efforts to promote nuclear disarmament and non-proliferation", question) |
           grepl("Preventing people without vaccinations from entering public spaces and transportation would do more harm than good", question)  |
         grepl("Vaccines should be mandated for healthcare workers", question) |
         grepl("Businesses should be allowed to require proof of vaccination for entry", question) |
         grepl("Businesses and institutions should be barred from discriminating based on vaccination status", question) |
         grepl("Schools should be allowed to require vaccinations for attendance", question) |
         grepl("All government-approved vaccines should be mandated", question)   |
           grepl("Implementing comprehensive background checks for all individuals entering the criminal justice system is necessary", question)  |
         grepl("Enhancing mental health support services for incarcerated individuals would be worth the cost and resources", question) |
         grepl("The use of solitary confinement as a punishment should be banned", question) |
         grepl("Inmates should have greater access to educational programs", question) |
         grepl("Non-violent offenders should be permitted to serve sentences through community service or house arrest", question) |
         grepl("The use of private prisons should be restricted", question) | 
           grepl("Same-sex marriage should remain legalized nationwide", question)  |
         grepl("Adoption rights should be granted to married same-sex couples", question) |
         grepl("Employment non-discrimination protections should be provided for gay and lesbian individuals", question) |
         grepl("Same-sex couples should receive spousal benefits (e.g. health insurance; survivor benefits)", question) |
         grepl("It is not right to provide the same federal rights and support for same-sex couples as opposite-sex couples", question) |
         grepl("Discrimination against same-sex couples in housing and public accommodations should be banned", question)
           ) %>%
  filter(grepl('pre-convo', phase)) %>%
  group_by(prolific_subject_id) %>%
  summarize(
    condition = first(condition),
    total_score = sum(as.numeric(answer), na.rm = TRUE),
    pre_mean_score = mean(as.numeric(answer), na.rm = TRUE),
    min_score = min(as.numeric(answer), na.rm = TRUE),
    max_score = max(as.numeric(answer), na.rm = TRUE)
  )


post_specific_polarization_df <- reverse_coded_scores_df %>%
  group_by(prolific_subject_id) %>%
  filter(grepl("Euthanasia should be allowed for terminally ill patients who request it", question) |
           grepl("Legal protections should be provided for doctors who perform euthanasia", question) | 
           grepl("It is not right for family members to request euthanasia on behalf of incapacitated patients", question) | 
           grepl("Euthanasia should only be allowed if the patient has received a psychological evaluation", question) |
           grepl("Euthanasia should be banned for patients with non-terminal conditions", question) |
           grepl("Euthanasia should be banned for all patients", question) |
           grepl("Euthanasia should not be performed at home", question) |
           grepl("Gender quotas should be implemented in corporate boards and executive positions", question)  |
         grepl("Mandating equal pay for equal work regardless of gender would improve gender equality", question) |
         grepl("Both mothers and fathers should be provided with parental leave", question) |
         grepl("Free childcare services should be provided to support working parents", question) |
         grepl("Funding for programs aimed at reducing gender-based violence should be increased", question) |
         grepl("Gender diversity should be encouraged in STEM fields through scholarships and grant", question) |
         grepl("Gender should be disregarded when selecting candidates for career advancement opportunities", question) |
           grepl("A universal healthcare system should be implemented in the U.S.", question)  |
         grepl("Medicaid should be expanded to cover more low-income individuals", question) |
         grepl("Prescription drug prices should be regulated to make them more affordable", question) |
         grepl("Government subsidies should be provided for private health insurance", question) |
         grepl("The government should negotiate drug prices with pharmaceutical companies", question) |
         grepl("Government funding should be increased for mental health services", question) |
         grepl("The competitive market should drive healthcare prices", question)
          | grepl("A memorial should be established in the U.S. to honor the victims of the bombings", question)  |
         grepl("The U.S. government should provide financial reparations to the survivors and their families", question) |
         grepl("The bombings were justified to bring a swift end to the war", question) |
         grepl("The bombings were morally wrong", question) |
         grepl("Learning about the atomic bombings of Hiroshima and Nagasaki is essential for understanding the consequences of nuclear warfare", question) |
         grepl("The U.S. should take responsibility for the humanitarian impact of the bombings", question) |
         grepl("The U.S. should participate in international efforts to promote nuclear disarmament and non-proliferation", question) |
           grepl("Preventing people without vaccinations from entering public spaces and transportation would do more harm than good", question)  |
         grepl("Vaccines should be mandated for healthcare workers", question) |
         grepl("Businesses should be allowed to require proof of vaccination for entry", question) |
         grepl("Businesses and institutions should be barred from discriminating based on vaccination status", question) |
         grepl("Schools should be allowed to require vaccinations for attendance", question) |
         grepl("All government-approved vaccines should be mandated", question)   |
           grepl("Implementing comprehensive background checks for all individuals entering the criminal justice system is necessary", question)  |
         grepl("Enhancing mental health support services for incarcerated individuals would be worth the cost and resources", question) |
         grepl("The use of solitary confinement as a punishment should be banned", question) |
         grepl("Inmates should have greater access to educational programs", question) |
         grepl("Non-violent offenders should be permitted to serve sentences through community service or house arrest", question) |
         grepl("The use of private prisons should be restricted", question) | 
           grepl("Same-sex marriage should remain legalized nationwide", question)  |
         grepl("Adoption rights should be granted to married same-sex couples", question) |
         grepl("Employment non-discrimination protections should be provided for gay and lesbian individuals", question) |
         grepl("Same-sex couples should receive spousal benefits (e.g. health insurance; survivor benefits)", question) |
         grepl("It is not right to provide the same federal rights and support for same-sex couples as opposite-sex couples", question) |
         grepl("Discrimination against same-sex couples in housing and public accommodations should be banned", question)
           ) %>%
  filter(grepl('post-convo', phase)) %>%
  group_by(prolific_subject_id) %>%
  summarize(
    condition = first(condition),
    total_score = sum(as.numeric(answer), na.rm = TRUE),
    post_mean_score = mean(as.numeric(answer), na.rm = TRUE),
    min_score = min(as.numeric(answer), na.rm = TRUE),
    max_score = max(as.numeric(answer), na.rm = TRUE)
  )
```

```{r}
#| label:  Get pre- and post- intervention mean scores for willingness offending reason questions
#| include: false

pre_offending_reason_df <- reverse_coded_scores_df %>%
   group_by(prolific_subject_id) %>%
  filter(grepl("offending-reason", question)) %>%
  filter(grepl('pre-convo', phase)) %>%
  group_by(prolific_subject_id) %>%
  summarize(
    condition = first(condition),
    total_score = sum(as.numeric(answer), na.rm = TRUE),
    pre_mean_score = mean(as.numeric(answer), na.rm = TRUE),
    min_score = min(as.numeric(answer), na.rm = TRUE),
    max_score = max(as.numeric(answer), na.rm = TRUE)
  )

post_offending_reason_df <- reverse_coded_scores_df %>%
   group_by(prolific_subject_id) %>%
  filter(grepl("reason-of-avoidance-post", question) | grepl("offending-reason", question)) %>%
  filter(grepl('post-convo', phase)) %>%
  group_by(prolific_subject_id) %>%
  summarize(
    condition = first(condition),
    total_score = sum(as.numeric(answer), na.rm = TRUE),
    post_mean_score = mean(as.numeric(answer), na.rm = TRUE),
    min_score = min(as.numeric(answer), na.rm = TRUE),
    max_score = max(as.numeric(answer), na.rm = TRUE)
  )

```

```{r}
#| label:  Get pre- and post- intervention mean scores for open-mindedness
#| include: false

pre_openmindedness_df <- reverse_coded_scores_df %>%
   group_by(prolific_subject_id) %>%
  filter(grepl("openmindedness", question)) %>%
  filter(grepl('pre-convo', phase)) %>%
  group_by(prolific_subject_id) %>%
  summarize(
    condition = first(condition),
    total_score = sum(as.numeric(answer), na.rm = TRUE),
    pre_mean_score = mean(as.numeric(answer), na.rm = TRUE),
    min_score = min(as.numeric(answer), na.rm = TRUE),
    max_score = max(as.numeric(answer), na.rm = TRUE)
  )


post_openmindedness_df <- reverse_coded_scores_df %>%
   group_by(prolific_subject_id) %>%
  filter(grepl("openmindedness", question)) %>%
  filter(grepl('post-convo', phase)) %>%
  group_by(prolific_subject_id) %>%
  summarize(
    condition = first(condition),
    total_score = sum(as.numeric(answer), na.rm = TRUE),
    post_mean_score = mean(as.numeric(answer), na.rm = TRUE),
    min_score = min(as.numeric(answer), na.rm = TRUE),
    max_score = max(as.numeric(answer), na.rm = TRUE)
  )

```

```{r}
#| label: Get pre- and post- intervention mean scores for slider questions
#| include: false

pre_sliders_df <- sliders_df %>%
   group_by(prolific_subject_id) %>%
  filter(grepl('pre-convo', phase)) %>%
  group_by(prolific_subject_id) %>%
  summarize(
    condition = first(condition),
    total_score = sum(as.numeric(answer), na.rm = TRUE),
    pre_mean_score = mean(as.numeric(answer), na.rm = TRUE),
    min_score = min(as.numeric(answer), na.rm = TRUE),
    max_score = max(as.numeric(answer), na.rm = TRUE)
  )

post_sliders_df <- sliders_df %>%
   group_by(prolific_subject_id) %>%
  filter(grepl('post-convo', phase)) %>%
  group_by(prolific_subject_id) %>%
  summarize(
    condition = first(condition),
    total_score = sum(as.numeric(answer), na.rm = TRUE),
    post_mean_score = mean(as.numeric(answer), na.rm = TRUE),
    min_score = min(as.numeric(answer), na.rm = TRUE),
    max_score = max(as.numeric(answer), na.rm = TRUE)
  )

```

```{r}
#| label: Get pre- and post- intervention mean scores for political party questions
#| include: false

pre_politics_df <- reverse_coded_scores_df %>%
   group_by(prolific_subject_id) %>%
  filter(grepl("pre-rating-republicans", question) | grepl("pre-interacting-with-republicans", question) | grepl("pre-rating-democrats", question) | grepl("pre-interacting-with-democrats", question)) %>%
  group_by(prolific_subject_id) %>%
  summarize(
    condition = first(condition),
    total_score = sum(as.numeric(answer), na.rm = TRUE),
    pre_mean_score = mean(as.numeric(answer), na.rm = TRUE),
    min_score = min(as.numeric(answer), na.rm = TRUE),
    max_score = max(as.numeric(answer), na.rm = TRUE)
  )

post_politics_df <- reverse_coded_scores_df %>%
   group_by(prolific_subject_id) %>%
  filter(grepl("rating-republicans-post", question) | grepl("interacting-with-republicans-post", question) | grepl("rating-democrats-post", question) | grepl("interacting-with-democrats-post", question)) %>%
  group_by(prolific_subject_id) %>%
  summarize(
    condition = first(condition),
    total_score = sum(as.numeric(answer), na.rm = TRUE),
    post_mean_score = mean(as.numeric(answer), na.rm = TRUE),
    min_score = min(as.numeric(answer), na.rm = TRUE),
    max_score = max(as.numeric(answer), na.rm = TRUE)
  )

```

```{r}
#| label: T-tests with all topics lumped together 
#| echo: false

t_test_politics <- t.test(pre_politics_df$pre_mean_score[pre_politics_df$condition != 'control free reflection'], post_politics_df$post_mean_score[post_politics_df$condition != 'control free reflection'], paired = TRUE)

t_test_polarization <- t.test(pre_polarization_df$pre_mean_score[pre_polarization_df$condition != 'control free reflection'], post_polarization_df$post_mean_score[post_polarization_df$condition != 'control free reflection'], paired = TRUE)

t_test_sliders <- t.test(pre_sliders_df$pre_mean_score[pre_sliders_df$condition != 'control free reflection'], post_sliders_df$post_mean_score[post_sliders_df$condition != 'control free reflection'], paired = TRUE)

t_test_offending_reason <- t.test(pre_offending_reason_df$pre_mean_score[pre_offending_reason_df$condition != 'control free reflection'], post_offending_reason_df$post_mean_score[post_offending_reason_df$condition != 'control free reflection'], paired = TRUE)

t_test_openmindedness <- t.test(pre_openmindedness_df$pre_mean_score[pre_openmindedness_df$condition != 'control free reflection'], post_openmindedness_df$post_mean_score[post_openmindedness_df$condition != 'control free reflection'], paired = TRUE)
```

```{r}
#| label: Extract t-test values
#| echo: false 

# politics 
politics_t_value <- round(t_test_politics$statistic, 3)
politics_ci <- round(t_test_politics$conf.int, 3)
politics_p_val <- round(t_test_politics$p.value, 3)
politics_significance_status <- ifelse(politics_p_val < 0.05, "a statistically significant difference", "no statistically significant difference")

# polarization
polarization_t_value <- round(t_test_polarization$statistic, 3)
polarization_ci <- round(t_test_polarization$conf.int, 3)
polarization_p_val <- round(t_test_polarization$p.value, 3)
polarization_significance_status <- ifelse(polarization_p_val < 0.05, "a statistically significant difference", "no statistically significant difference")

# sliders
sliders_t_value <- round(t_test_sliders$statistic, 3)
sliders_ci <- round(t_test_sliders$conf.int, 3)
sliders_p_val <- round(t_test_sliders$p.value, 3)
sliders_significance_status <- ifelse(sliders_p_val < 0.05, "a statistically significant difference", "no statistically significant difference")

# openmindedness
openmindedness_t_value <- round(t_test_openmindedness$statistic, 3)
openmindedness_ci <- round(t_test_openmindedness$conf.int, 3)
openmindedness_p_val <- round(t_test_openmindedness$p.value, 3)
openmindedness_significance_status <- ifelse(openmindedness_p_val < 0.05, "a statistically significant difference", "no statistically significant difference")

# offending_reason
offending_reason_t_value <- round(t_test_offending_reason$statistic, 3)
offending_reason_ci <- round(t_test_offending_reason$conf.int, 3)
offending_reason_p_val <- round(t_test_offending_reason$p.value, 3)
offending_reason_significance_status <- ifelse(offending_reason_p_val < 0.05, "a statistically significant difference", "no statistically significant difference")

```

```{r}
#| label: Conversation raw transcript df
#| echo: false

## make raw conversations df with subject_id and condition. remove keypresslog 
conversations_rawwww_df <- raw_df %>%
  filter(trial_type == "chat") %>%
  select(prolific_subject_id, logs, condition) 

# merge with conversations df 
conversations_raw_df <- conversations_rawwww_df %>%
  mutate(across(everything(), ~ gsub("keyPressLog.*?\\]}", '', .))) %>%
  left_join(full_prolific_demographics_df, by = "prolific_subject_id") %>%
  select(prolific_subject_id, logs, condition, pilot_iteration)

```

```{r}
#| label: Parse combo bot transcripts for readability 
#| echo: false

##  clean chain bot  
conversations_df_combo <- conversations_raw_df %>%
  # filter for combo only 
  filter(condition == "combination bot") %>%
  #remove system content (chatbot prompts)
    mutate(across(everything(), ~ gsub('"role":"system","content".*?\\},', '', .))) %>%
  #remove welcome to chatroom message
    mutate(across(everything(), ~ gsub('"role":"system-prompt","content".*?\\},', '', .))) %>%
  #rename to clarify chatbot's first message. include | so that we can use it as a delimiter later
    mutate(across(everything(), ~ gsub('"role":"chatbot","content"', '|FIRST MESSAGE', .))) %>%
  #rename to clarify user messages
    mutate(across(everything(), ~ gsub('"role":"user","content"', '|USER', .))) %>%
  #rename to clarify bot messages
    mutate(across(everything(), ~ gsub('"role":"assistant","content"', '|BOT', .))) %>%
  #rename to clarify the content that the first bot passes to the second bot in the chain
    mutate(across(everything(), ~ gsub('"role":"chain-prompt"', "|CHAIN PROMPT", .))) %>%
  mutate(across(everything(), ~ gsub('\\}\\],"time"', ',"time"', .))) 

# the mutates make the user and bot strings within the chain prompt look like they were actual exchanges in the conversations. when i tried to fix this, gsub wasn't parsing special characters right even with escapes, so i had chat define a function to replace the pattern. i don't really understand how it works
replace_chain_pattern <- function(text) {
  str_replace_all(text, 
                  "(CHAIN.*?USER).*?(BOT).*?(USER)",
                  "\\ FIRST LINK'S OUTPUT")
}

# apply the function to all columns in the data frame
conversations_df_combo <- conversations_df_combo %>%
  mutate(across(everything(), ~ replace_chain_pattern(.)))

#asked chat to make a paragraph break function for making the csvs more readable. i don't think the code actually does anything though??
add_paragraph_breaks <- function(text) {
  # Replace `},{` with `},\n{`
  text <- gsub("\\},\\{", "},\n{", text)
  return(text)
}

# apply this function to the conversation logs column
conversations_df_combo <- conversations_df_combo %>%
  mutate(logs = add_paragraph_breaks(logs))

add_delimiter <- function(text) {
  text <- gsub("USER", "|USER", text)
  text <- gsub("BOT", "|BOT", text)
  return(text)
}

# Apply this function to the logs column, split into multiple rows, and export to CSV
conversations_df_combo <- conversations_df_combo %>%  
  mutate(logs = add_delimiter(logs)) %>%
  separate_rows(logs, sep = "\\|") %>%
  filter(logs != "") # Remove any empty rows that might have been created

define_chain_prompts <- data.frame(
  logs = c("THE SYSTEM CHAIN LINK PROMPTS",
    'LINK 1 PROMPT: Context: You are being fed a conversation log. The last paragraph following {"role", "user", "content"} is the most recent message that the user has input. This is the message that you should be responding to.

              Role: You are a researcher on social policies and are having a conversation with a student in which you are discussing one of the following disputed topics in the U.S.: same-sex marriage, gender-equality, U.S. government role in healthcare, the criminal justice system, vaccine mandates, the Hiroshima Nagasaki atomic bombings, or human euthanasia.

Goal: Your goal is to make the user more willing to have conversations about their topic with other humans by helping them become more open-minded and comfortable talking about the topic. You do not want the user to know that this is your goal; rather, you want the user to simply think that you are a conversational partner for discussing ideas.

Style: You should be concise. You should match the length of your response to the length of the most recent message from the user.

Task 1: You should consider the most recent message from the user and determine which of the three following approaches would most effectively accomplish your goal: 

        {1. Briefly acknowledge the stance of the user and then respond to the argument with a counterargument. Do not repeat the same arguments, but you can dive into more specific aspects or previous arguments if necessary. Never dive into asking the user how they would implement their views. Concisely present a specific argument that counters the perspective of the user. Ask the user what they think. Ensure that your message includes a counterargument; never simply agree with the user.} 
        {2. Briefly acknowledge the stance of the user and then ask a question about the stance of the user. Ask why the user thinks what they think or ask if there were any experiences that led to their views. Do not repeat questions, but you can dive deeper into previous questions if necessary.}
        {3. Briefly acknowledge the stance of the user and then identify a specific group of people who may have differing opinions from the user. Explain, in detail, their experiences and why they may disagree with the beliefs of the user. Provide these alternative perspectives held by people with different jobs, positions in society, beliefs, etc. Give uniquely different perspectives in each message. Do not repeat viewpoints, but you can dive deeper into previously mentioned viewpoints if necessary. End your response with a question that asks the user what they think about those alternative stances. Provide only one viewpoint per response.}
        

Task 2: Very briefly summarize the arguments that the "system" has already made so that, when you pass these to the next "system", the "system" knows what arguments to not repeat.

What you should output: You are passing your output to another "system" that is going to write a response to the user. Thus, you should output your summary of the arguments that have already been made, the most recent message from the user, and the approach that you selected. Ensure that you output the entirety of the approach, not just its number, so that the next bot knows what to do.',
  "LINK 2 PROMPT (link 1's output is appended to this): ",
  "CONVERSATIONS"
  ),
  stringsAsFactors = FALSE
)

#merge them 
conversations_df_combo <- bind_rows(define_chain_prompts, conversations_df_combo)

```

```{r}
#| label: Parse selection bot transcripts
#| echo: false

conversations_df_selection <- conversations_raw_df %>%
  # filter for combo only 
  filter(condition == "selection bot") %>%
    # remove keypresslog
    mutate(across(everything(), ~ gsub("keyPressLog.*?\\]}", '', .))) %>%
  #remove system content (chatbot single prompts and prompt within the chain prompt)
    mutate(across(everything(), ~ gsub('"role":"system","content".*?\\},', '', .))) %>%
  #remove welcome to chatroom message
    mutate(across(everything(), ~ gsub('"role":"system-prompt","content".*?\\},', '', .))) %>%
  #rename to clarify chatbot's first message. include | so that we can use it as a delimiter later
    mutate(across(everything(), ~ gsub('"role":"chatbot","content"', '|FIRST MESSAGE', .))) %>%
  #rename to clarify user messages
    mutate(across(everything(), ~ gsub('"role":"user","content"', '|USER', .))) %>%
  #rename to clarify bot output messages
    mutate(across(everything(), ~ gsub('"role":"assistant","content"', '|BOT', .))) %>%
  #rename to clarify the responses that the bot generated for election
    mutate(across(everything(), ~ gsub('"role":"selection_prompt","content"', '|THREE RESPONSE OPTIONS', .))) %>%
  #rename the |USER inside the selection prompt because it should be a delimiter later 
    mutate(across(everything(), ~ gsub('\\|USER:"\\(0\\)', '(0)', .)))

#delimit text 
conversations_df_selection <- conversations_df_selection %>%  
  separate_rows(logs, sep = "\\|") %>%
  filter(logs != "") # Remove any empty rows that might have been created

#make some rows that document what the selection bot was prompted with 
define_selection_prompts <- data.frame(
  logs = c("PROMPTS TO EACH OF THE RESPONSE-GENERATING BOTS:","COUNTER BOT: Role: Your role is to be a policy education expert with whom people can discuss their beliefs about contentious topics. 
                Style: You should match the length of your response to the length of the most recent 'role':'user':'content'. You should be conversational but use technically precise language. Be concise.
                Task: You should always concisely respond to the other person's argument with a counterargument. Do not repeat the same arguments that the 'role: assistant' has brought up before, but you can dive into more specific aspects or previous arguments. You should never dive into asking the user how they would implement their views. You should always concisely present a specific argument that counters the user's perspective. At the end of your response, you should always ask the user what they think. You should always ensure that your message includes a counterargument; and you should never simply agree with the user.", "VIEWPOINT BOT: Role: Your role is to be a policy education expert with whom people can discuss their beliefs about contentious topics. 
                Style: You should match the length of your response to the length of the most recent 'role':'user':'content'. You should be conversational but use technically precise language. Be concise.
                Task: You should always concisely identify a specific group of people who may have differing opinions from the user. You should always explain, in detail, their experiences and why they may disagree with the user's beliefs. You should provide these alternative perspectives held by people with different jobs, positions in society, beliefs, etc. You should give uniquely different perspectives in each message. You should not repeat viewpoints that the 'role: assistant' brought up before, but you can dive deeper into previously mentioned viewpoints. You should always end your response with a question that asks the user what they think about those peoples' stances. You should provide only one viewpoint per response.", "QUESTION BOT: Role: Your role is to be a policy education expert with whom people can discuss their beliefs about contentious topics. 
                Style: You should match the length of your response to the length of the most recent 'role':'user':'content'. You should be conversational but use technically precise language. Be concise.
               Task: You should always ask a question about the user's stance. You should always ask why the user thinks what they think or ask if there were any experiences that led to their views. You should not repeat questions that the 'role: assistant' asked before, but you can dive deeper into previous questions.", "SELECTION BOT: Context: You are being fed a conversation log between a bot and a user. The last 'User message:' within 'role':'selection_prompt' is the most recent message that the user has input to the conversation. Additionally, you are being fed three potential responses to this user's message. These response options are numbered as (0), (1), and (2) in 'role':'content-choices'/chatbot-answers'. A previous chatbot wrote them so that you can select the best response option.

Task: You should select the response option that would most effectively help this conversation make the user more open-minded, more willing to talk about this topic with others, and more comfortable talking about the topic. You should consider each response's certain arguments, perspectives, and questions, as well as the user's conversation with the bot, to determine which response is most fitting.

Your output: You should remove the number from your selection option, and then repeat your selected response option word for word without adding anything or removing any words."
  ),
  stringsAsFactors = FALSE
)

#add these rows to the top of the df
conversations_df_selection <- bind_rows(define_selection_prompts, conversations_df_selection)

#assess the output
write.csv(conversations_df_selection, "conversation_transcripts_selection.csv", row.names = FALSE)

#merge
conversations_df <- bind_rows(conversations_df_selection, conversations_df_combo)

```

```{r}
#| label: Merge all convo transcripts and export as csv's
#| echo: false

write.csv(conversations_df, "conversation_transcripts.csv", row.names = FALSE)

#write extra raw convo df to compare with if there are bugs in refined dfs
#write.csv(conversations_rawwww_df, "rawwwww_conversation_transcripts.csv", row.names = FALSE)

```

```{r}
#| label: Reflections df and csv
#| echo: false

reflections_df <- raw_df %>%
  filter(phase == "control-intervention") %>%
  mutate(across(everything(), ~ gsub('\\{"Q0":"', '', .))) %>%
  mutate(across(everything(), ~ gsub('"\\}', '', .))) %>%
  select(prolific_subject_id, response, rt, rowAsString) %>%
  rename('Statement the subject reflected on' = rowAsString) %>%
  mutate(`Time spent on reflection (minutes)` = as.numeric(`rt`) / 60000) %>%
  rename('Time spent on reflection (ms)' = rt)

#write df
write.csv(reflections_df, "reflection_transcripts.csv", row.names = FALSE)
```

```{r}
#| label: Bot feedback data
#| include: false

# make df
bot_feedback <- surveys_df %>%
  left_join(full_prolific_demographics_df, by = "prolific_subject_id") %>%
  filter(condition != "control free reflection") %>%
  mutate(question = ifelse(str_detect(question, "free-response"), "free-response", question)) %>%
    mutate(question = ifelse(str_detect(question, "convo-effect-on-willingness"), "convo-effect-on-willingness", question)) %>%
    mutate(question = ifelse(str_detect(question, "new-perspective"), "new-perspective", question)) %>%
    mutate(question = ifelse(str_detect(question, "still-contributes"), "still-contributes", question)) %>%
    mutate(question = ifelse(str_detect(question, "feelings-about-bot"), "feelings-about-bot", question)) %>%
  filter(question == "free-response" | question == "convo-effect-on-willingness" | question == "new-perspective" | question == "still-contributes" | question == "feelings-about-bot") %>%
  arrange(desc(prolific_subject_id)) %>%
  select(prolific_subject_id, question, answer, condition, pilot_iteration.x, topicChoiceAsString) %>%
  mutate(word_count = str_count(answer, '\\S+')) %>%
  mutate(question = as.character(question))

# add some entries that explain what the questions were 
define_bot_feedback_questions <- data.frame(
  question = c("THE FULL QUESTIONS",
    "free-response: After your conversation with the chat bot, do you feel more willing to have a conversation with others about [topic]? Please freely reflect in the space below.",
  "convo-effect-on-willingness: What parts of this conversation, if any, affected your willingness to talk with someone who has different views about [topic]? What made you feel like the conversation was or was not productive?", 
  "new-perspective: Throughout this conversation, were there any moments that opened you up to a new perspective about [topic]? If so, what occurred in these moments? If not, what made you feel like the conversation was not productive?", 
  "still-contributes: What still contributes to your willingness or unwillingness to converse with others about [topic]? Please freely reflect in the space below.", 
  "feelings-about-bot: We are still working on improving our chatbot. How did you like talking with the bot? What do you wish were different? Please provide any feedback regarding your conversation that we have not already covered.",
  "DATA"
  ),
  stringsAsFactors = FALSE
) %>%
  mutate(question = as.character(question))

#merge them 
bot_feedback_for_csv <- bind_rows(define_bot_feedback_questions, bot_feedback)

  
write.csv(bot_feedback_for_csv, "bot_feedback.csv", row.names = FALSE)
```

```{r}
#| label: Make new dfs for finding time taken in interventions
#| echo: false

#make data frame that 
chatbot_time_df <- raw_df %>%
  group_by(prolific_subject_id) %>%  
  filter(condition != 'control free reflection') %>%
#add up each subject's rts to find total time (not including chatbot convo bc we only logged chat time in the transcripts) spent doing experiment
  mutate(summed_rt = sum(as.numeric(rt), na.rm = TRUE)) %>%
#easier while figuring out the different time metrics to convert into minutes
  mutate(summed_rt_minutes = summed_rt / 60000) %>%
#elapsed time is measured since the subject started the experiment. so, elapsed time at the last phase of the experiment (goodbye) is the total time spent on the experiment 
  filter(phase == 'goodbye') %>%
  mutate(time_elapsed_minutes = as.numeric(time_elapsed) / 60000) %>%
  # select what we want because there are a lot of columns 
  select(prolific_subject_id, summed_rt, time_elapsed, summed_rt_minutes, time_elapsed_minutes) %>%
#subtract summed time from elapsed time to see how long people spent on chat 
  mutate(chatbot_time = time_elapsed - summed_rt) %>%
  mutate(chatbot_time_minutes = chatbot_time / 60000) %>%
  ungroup()

reflections_time_df <- reflections_df %>%
  select(prolific_subject_id, 'Time spent on reflection (ms)', 'Time spent on reflection (minutes)')
```

```{r}
#| label: Time taken on surveys
#| echo: false 

#Find time taken on first survey and time taken on second survey. Also subtract for the different. Also, look at whether there's a difference for control people versus chatbot people

#finding time taken on pre survey
pre_intervention_survey_time_df <- raw_df %>%
  filter(grepl('survey', phase), grepl('pre', phase)) %>%
  group_by(prolific_subject_id) %>%
  mutate(pre_time_minutes = sum(as.numeric(rt) / 60000, na.rm = TRUE)) %>%
  select(prolific_subject_id, condition, pre_time_minutes)

#removing duplicate rows
pre_intervention_survey_time_df <- unique(pre_intervention_survey_time_df)

#finding time taken on post survey
post_intervention_survey_time_df <- raw_df %>%
  filter(grepl('survey', phase), grepl('post', phase)) %>%
  group_by(prolific_subject_id) %>%
  mutate(post_time_minutes = sum(as.numeric(rt) / 60000, na.rm = TRUE)) %>%
  select(prolific_subject_id, post_time_minutes)

#removing duplicates
post_intervention_survey_time_df <- unique(post_intervention_survey_time_df)

#merge dfs to view differences 
survey_time_df <- pre_intervention_survey_time_df %>%
  full_join(post_intervention_survey_time_df, by = "prolific_subject_id") %>%
  mutate(difference_pre_post_time_minutes = pre_time_minutes - post_time_minutes) %>%
  ungroup()

```

```{r}
#| label: Word counts
#| echo: false

bot_feedback_word_counts <- bot_feedback %>%
  filter(!is.na(word_count))

conversations_messages_word_counts <- conversations_df %>%
  filter(grepl('USER', logs)) %>%
  mutate(across(everything(), ~ gsub('","time":.*', '', .))) %>%
  mutate(across(everything(), ~ gsub('USER:"', '', .))) %>%
  mutate(conversation_word_count = str_count(logs, '\\S+')) %>%
  group_by(prolific_subject_id) %>%
  mutate(avg_convo_message_word_count = mean(as.numeric(conversation_word_count), na.rm = TRUE)) %>%
  select(prolific_subject_id, avg_convo_message_word_count, logs, conversation_word_count)

reflections_word_counts <- reflections_df %>% 
  mutate(reflection_word_count = str_count(response, '\\S+')) %>%
  group_by(prolific_subject_id) %>%
  mutate(avg_reflection_word_count = mean(as.numeric(reflection_word_count), na.rm = TRUE)) %>%
  select(prolific_subject_id, avg_reflection_word_count, response, reflection_word_count)

```

```{r}
#| label: Values from word count & time spent 
#| include: false 

average_chatbot_time <- round(mean(chatbot_time_df$chatbot_time_minutes, na.rm = TRUE), 1)

range_chatbot_time <- round(range(chatbot_time_df$chatbot_time_minutes, na.rm = TRUE), 1)

average_reflection_time <- round(mean(reflections_time_df$`Time spent on reflection (minutes)`, na.rm = TRUE), 1)

range_reflection_time <- round(range(reflections_time_df$`Time spent on reflection (minutes)`, na.rm = TRUE), 1)

avg_bot_feedback_word_count <- round(mean(bot_feedback_word_counts$word_count, na.rm = TRUE), 1)

range_bot_feedback_word_count <- round(range(bot_feedback_word_counts$word_count, na.rm = TRUE), 1)

avg_conversation_word_count <- round(mean(conversations_messages_word_counts$conversation_word_count), 1)

range_conversation_word_count <- round(range(conversations_messages_word_counts$conversation_word_count), 1)

avg_reflection_word_count <- round(mean(reflections_word_counts$reflection_word_count), 1)

range_reflection_word_count <- round(range(reflections_word_counts$reflection_word_count), 1)

```

```{r}
#| label: Extracting values for results section 
#| echo: false 


```

```{r}
#| label: tbl-basic-demographics-table
#| echo: false
#| tbl-cap: Table of basic demographics.

#we already read in demographics earlier 

#create a demographics table from the demographics questions in our survey. turn the demographics questions from question column into their own columns with answer as the entries within the column
survey_demographics_df <- surveys_df %>%
filter(question == 'ethnicity' | question == 'political-affiliation' | question == 'gender-identification' | question == 'education-level' | question == 'religious-affiliation' | question == 'political-ideology') %>%
select(question, answer, prolific_subject_id, condition) %>%
pivot_wider(names_from = question, values_from = answer)

#merge our two demographics tables
demo_table_df <- survey_demographics_df %>%
  left_join(full_prolific_demographics_df, by = "prolific_subject_id", suffix = c("_prolific", ""))

#make a region column because showing each state is excessive
demo_table_df$Region <- ifelse(demo_table_df$`Current u.s state of residence` %in% c("California (CA)", "Colorado (CO)", "Utah (UT)", "Utah(UT)", "Idaho (ID)", "Alaska (AK)", "Hawaii (HI)", "Washington (WA)", "Oregon (OR)", "Nevada (NV)", "New Mexico (NM)", "Montana (MT)", "Arizona (AZ)", "Wyoming (WY)"), "West",
                     ifelse(demo_table_df$`Current u.s state of residence` %in% c("Texas (TX)", "Florida (FL)", "Georgia (GA)", "North Carolina (NC)", "Tennessee (TN)", "South Carolina (SC)", "Alabama (AL)", "Mississippi (MS)", "Louisiana (LA)", "Delaware (DE)", "Maryland (MD)", "Virginia (VA)", "Washington, D.C. (DC)", "West Virginia (WV)", "Kentucky (KY)", "Arkansas (AR)", "Oklahoma (OK)"), "South",
                            ifelse(demo_table_df$`Current u.s state of residence` %in% c("New York (NY)", "New Jersey (NJ)", "Massachusetts (MA)", "Pennsylvania (PA)", "Connecticut (CT)", "Rhode Island (RI)", "Vermont (VT)", "New Hampshire (NH)", "Maine (ME)"), "Northeast",
                                   ifelse(demo_table_df$`Current u.s state of residence` %in% c("Michigan (MI)", "Illinois (IL)", "Ohio (OH)", "Indiana (IN)", "Wisconsin (WI)", "Minnesota (MN)", "Iowa (IA)", "Missouri (MO)", "Kansas (KS)", "Nebraska (NE)", "South Dakota (SD)", "North Dakota (ND)"), "Midwest", NA))))


# define the levels in categorical variables so that they are organized in the table 
demo_table_df$'political-affiliation' <- fct_relevel(
  demo_table_df$'political-affiliation',
  "Republican",
  "Democrat",
  "Independent",
)


demo_table_df$'education-level' <- fct_relevel(
  demo_table_df$'education-level',
  "High school diploma or GED",
   "Some college; no degree",
  "Associate degree",
  "Bachelor's degree",
   "Master's degree",
)


demo_table_df$'political-ideology' <- fct_relevel(
  demo_table_df$'political-ideology',
"Very conservative",
"Conservative",
"Somewhat conservative",
"Moderate",
"Somewhat liberal",
"Liberal",
"Very liberal"
)

demo_table_df <- demo_table_df %>%
  mutate(across(where(is.factor), ~ droplevels(.)))

demographics_table <- tbl_summary(demo_table_df,
 by = NULL,
  label = list(
    `Time taken (minutes)` = "Time taken (minutes)",
    `Region` = "Current U.S. region of residence",
    Age = "Age (years)",
    Sex = "Sex",
    `Ethnicity simplified` = "Ethnicity simplified",
    `political-affiliation` = "Political affiliation",
    `education-level` = "Education level",
    `religious-affiliation` = "Religious affiliation",
    `political-ideology` = "Political ideology"
  ),
  statistic = NULL,
#list(
  #  all_continuous() ~ "{mean} ({sd})",
  #  all_categorical() ~ "{n} ({p}%)"
#),
  type = list(
    `Time taken (minutes)` = "continuous",
    `Region` = "categorical",
    `Age` = "continuous",
    `gender-identification` = "categorical",
   `Sex` = "categorical",
    `Ethnicity simplified` = "categorical",
    `political-affiliation` = "categorical",
    `education-level` = "categorical",
    `religious-affiliation` = "categorical",
    `political-ideology` = "categorical"
  ),
  digits = list(
    all_continuous() ~ 2,
    all_categorical() ~ 0
  ),
  value = NULL,
  missing = NULL,
  missing_text = NULL,
  sort = NULL,
  percent = NULL,
 include = c(
'Time taken (minutes)', 
'Region', 
'Age', 
'Sex', 
'Ethnicity simplified', 
'political-affiliation', 
'education-level', 
'religious-affiliation', 
'political-ideology'
))
 # %>%  modify_header(label = "**whatever label i want**")

# Print the table
as_gt(demographics_table)

```

### Materials

We used custom software written with the jsPsych framework (@jspsychcite), which participants viewed and responded to via their personal laptops or desktops. The javascript code for the experiment and data analysis can be found at (https://github.com/jodeleeuw/URSI-LLM-Convo-Bot/tree/main/pilot_1). Pre-registration and all data for this study and previous pilots are available at https://osf.io/x32pv.

#### Intervention development

There are findings from human-to-human research on approaches, techniques, and situational factors that can make people more willing to have conversations on controversial topics and be more productive/open-minded. 

Some cognitive scientists have found that inviting people to explain, rather than freely reflect on, a contentious political issue may help reduce intergroup toxicity in these discussions (@fernbach2013. @fernbach2013 explained that the attempt to explain the issue often leads people to become confronted with their lack of understanding, which in turn might lead them to become more moderate as well as less hostility towards political outgroup members. However, subsequent scholarship either found no evidence for the effect (Crawford & Ruscio, 2021) or found it to be constrained to specific topics (Sloman & Vives, 2022) or personalities (Voelkel, Brandt, & Colombo, 2018). That is, inviting people to explain specific policy positions did not consistently lead to less extreme policy positions, nor did it influence how they felt about political partisans. Another possibility is that explanations might still hold some promise, changing the process of how people think rather than the content of what people believe. Specifically, inviting people to explain themselves could encourage information search via consulting others’ viewpoints and integration of multiple perspectives, opening the door for wiser, more open-minded political thinking (Baron, 2019; Grossmann et al., 2021; Grossmann & Kross, 2014; Kross & Ayduk, 2017; Stanovich & West, 1997; see Grossmann et al., 2021, Porter et al., 2022, for reviews). 

Research has also found that inviting people to explain a problem to somebody who is unfamiliar with the topic can increase open-mindedness (@elnakouri2024).

Though the findings were abundant and there were thus a myriad of approaches which we could have taken, we extracted three general approaches: providing counterarguments, asking questions about the user's views, and explaining why others might have alternative perspectives. \[cite the research for each one\].

The chatbot that we created for this experiment uses a response election approach: four chatbots, each with a different chat completion prompt, generate a unique response to a user message. Then, a final chatbot selects and outputs one of the responses. Three of the four approaches were those gathered in the human-to-human research. The fourth approach gave the bot as much agency as possible in its choice of response through the most minimal prompting that still produced a conversational response (see Appendix: Prompts). We developed these prompts through methods suggested by leading guides on prompt engineering (cite) and iterative refinement until we reached a satisfactory result. In this way, we hoped to give the chatbot two opportunities to affect users: either through our manipulation of its capabilities or through its own manipulation.

[discuss @matz2024 and personalizing the chatbot style ]

```{r}
#| label: flowchart-selection-bot
#| echo: false
#| tbl-cap: Graphic of selection bot process.

grViz("
digraph chatbot_flow {
  
  graph [layout = dot, rankdir = LR]

  node [shape = note, style = filled, fillcolor = lightblue]

  user_input [label = 'User\\nmessage\\ninput']
  counter_response [label = 'Bot generates\\ncounter-argument\\nresponse', shape = box]
  question_response [label = 'Bot generates\\nquestion\\nresponse', shape = box]
  viewpoint_response [label = 'Bot generates\\nviewpoint\\nresponse', shape = box]
  bot_decision [label = 'Bot chooses\\nbest\\nresponse', shape = circle, width=1.2]
  final_output [label = 'Bot\\nmessage\\noutput']

  user_input -> counter_response
  user_input -> question_response
  user_input -> viewpoint_response

  counter_response -> bot_decision
  question_response -> bot_decision
  viewpoint_response -> bot_decision

  bot_decision -> final_output
}
")
```

![Chatbot conversation screenshot](intervention_screenshot.png)

#### Survey development

We measured the effectiveness of our chatbot through administering a survey before and after the experiment intervention. The questionnaire was composed of basic demographic questions, a question to ascertain which of our six topics the participant was most unwilling to discuss, and then our willingness survey questions. The key measures in the survey were open-mindedness, polarization of topic-specific beliefs, and willingness to converse. We drew on existing measures for open-mindedness and polarization of topic-specific opinions. Applicable measures for willingness to converse did not exist, so we created and then pretested our own based on existing research about the concerns or experiences that contribute to unwillingness to converse. This led us to find concepts such as Social Identity Theory (SIT), Emotional Dysregulation (ED), and Communication Avoidance (CA). Through these measures, we were able to observe whether the intervention changed open-mindedness, polarization of topic-specific beliefs, overall willingness to converse, and specific concerns that contributed to users' unwillingness to converse.

## open-mindedness so linked to willingness to converse
[Dolbier, K. L., Dieffenbach, S., & Lieberman, M. D. (2025). Open-Mindedness: An Integrative Review of Interventions. Current Opinion in Behavioral Sciences, 58, 101438. (This is a forthcoming or very recent review, indicating its up-to-date relevance).

Why it's a fit: This review explicitly focuses on open-mindedness and interventions to increase it. It discusses how interventions often target cognitive pathways (e.g., reducing biased thinking, promoting expansive mindsets) and affective pathways (emotion regulation to maintain composure when beliefs are challenged). These mechanisms are inherently activated when engaging with opposing views on controversial topics, as it requires confronting biases and managing emotional responses. It directly links open-mindedness to "willingness to nondefensively entertain alternative ideas" and "willingness to engage with dissenting opinions."]

### Procedure

Upon agreeing to participate in this experiment, participants were brought to the experiment webpage, http://54.234.217.37/jdeleeuw/ursi2024/experiment/experiment.html, where they were shown a welcome message and were told that they were going to fill out a questionnaire and then converse with a chatbot (experimental group) or perform a free reflection (control group). After completing the questionnaire, participants were sent back to Prolific.

## Results

We conducted our analyses in the R environment (R version 4.2.1; R Core Team, 2022), using several packages from the tidyverse (@tidyversecite), as well as the osfr (@osfrcite), ez (@ezcite), gt (@gtcite), gtsummary (@gtsummarycite), kableExtra (@kableExtracite), stringr (@stringrcite), and ggridges (@ggridgescite) packages. We performed the pre-registered analysis for the experiment.

On average, subjects spent `r average_chatbot_time` minutes with the chatbot (range `r range_chatbot_time`) and each message was `r avg_conversation_word_count` words long (range `r range_conversation_word_count`). Subjects averaged `r average_reflection_time` minutes on the control free reflection (range `r range_reflection_time`) with a reflection length of `r avg_reflection_word_count` words (range `r range_reflection_word_count`). Experimental group subjects averaged `r avg_bot_feedback_word_count` words in response to each post-intervention survey question that asked for feedback on the bot (range `r range_bot_feedback_word_count`).

```{r}
#| label: fig-time-plot
#| echo: false
#| fig-cap: Scatterplot with line of equality showing time spent on pre- and post-intervention surveys with color indicating whether subject was in control group or experimental group.

time_plot_df <- survey_time_df %>%
  full_join(reflections_time_df, by = "prolific_subject_id") %>%
  full_join(chatbot_time_df, by = "prolific_subject_id") %>%
  mutate(intervention_time_minutes = coalesce(as.numeric(`Time spent on reflection (minutes)`, na.rm = TRUE), as.numeric(chatbot_time_minutes, na.rm = TRUE))) %>%
  rename(Condition = condition) %>%
  select(Condition, pre_time_minutes, post_time_minutes, difference_pre_post_time_minutes, intervention_time_minutes) %>%
  arrange(desc(Condition)) %>%
  mutate_if(is.numeric, ~ round(., 2)) %>%
  ungroup() %>%
  mutate(condition_general = if_else(Condition == 'control free reflection', 'control', 'experimental'))


time_plot <- ggplot(time_plot_df, aes(x = pre_time_minutes, y = post_time_minutes, color = condition_general)) + labs(title = "Post- vs. Pre-Intervention Surveys", x = 'Time spent on pre-intervention survey (minutes)', y = 'Time spent on post-intervention survey (minutes)', color = "Experiment condition") +
  geom_point() + #scatterplot
  geom_abline(intercept = 0, slope = 1, color = "rosybrown1", linetype = "dashed") +  # Line of equality
  theme_minimal()  + 
  scale_color_manual(values = c("control" = "cornflowerblue", "experimental" = "darkseagreen"), 
                     labels = c("control" = "Control Group", "experimental" = "Experimental Group"))

print(time_plot)
```

```{r}
#| label: tbl-time-df
#| echo: false
#| tbl-cap: Table showing time spent on pre-intervention survey, post-intervention survey, difference in pre- and post-intervention survey times, and time spent on intervention. 

time_figure_df <- time_plot_df %>%
  group_by(Condition) %>%
  select(-condition_general) %>%
   # take all mean times by condition
  summarise(across(everything(), \(x) round(mean(x, na.rm = TRUE), 1))) %>%
  rename(
    'Pre-intervention survey time (minutes)' = pre_time_minutes,
    'Post-intervention survey time (minutes)' = post_time_minutes,
    'Difference in survey time (minutes)' = difference_pre_post_time_minutes,
    'Intervention time (minutes)' = intervention_time_minutes
  )

kable(time_figure_df)
```

### Scatterplots of subjects' pre- and post-intervention ratings on surveys

The politics t-test revealed a t-value of `r politics_t_value` with a p-value of `r politics_p_val`, indicating `r politics_significance_status` between the change in experimental group subjects' views of the opposing political party and control group subjects' change in views (95% CI: `r politics_ci`).

```{r}
#| label: fig-political-party-graph
#| echo: false
#| fig-cap: Scatterplot with line of equality of pre- and post-conversation mean ratings of opinions on the opposite party. Subjects rated their opinions on a scale from 0 to 7, where a rating of 0 was strongly negative and a rating of 7 was strongly positive.

merged_politics_df <- merge(pre_politics_df, post_politics_df, by = "prolific_subject_id")

politics_scatterplot <- ggplot(merged_politics_df, aes(x = pre_mean_score, y = post_mean_score, color = condition.x)) +
  geom_point() +  # Add points
  geom_abline(intercept = 0, slope = 1, color = "rosybrown1", linetype = "dashed") +  # Line of equality
  labs(x = "Pre-intervention mean rating", y = "Post-intervention mean rating", title = "Change in opinions of the opposite party", color = "Group") +
  scale_color_manual(values = c("control free reflection" = "darkseagreen", "selection bot" = "cornflowerblue", "combination bot" = "navyblue"), 
                     labels = c("control free reflection" = "Control group", "selection bot" = "Experimental group: Selection bot", "combination bot" = "Experimental group: Combination bot"))

print(politics_scatterplot)

```

The polarization t-test revealed a t-value of `r polarization_t_value` with a p-value of `r polarization_p_val`, indicating `r polarization_significance_status` between the change in experimental group subjects' topic-specific opinions and control group subjects' change in opinions (95% CI: `r polarization_ci`).

```{r}
#| label: fig-polarization-graph
#| echo: false
#| fig-cap: Scatterplot with line of equality of pre- and post-conversation mean ratings of opinions on topic-specific statements. Subjects rated their opinions on a scale from 0 to 7, where a rating of 0 meant subject strongly disagreed and a rating of 7 meant strongly agree.

merged_polarization_df <- merge(pre_polarization_df, post_polarization_df, by = "prolific_subject_id")

polarization_scatterplot <- ggplot(merged_polarization_df, aes(x = pre_mean_score, y = post_mean_score, color = condition.x)) +
  geom_point() +  # Add points
  geom_abline(intercept = 0, slope = 1, color = "rosybrown1", linetype = "dashed") +  # Line of equality
  labs(x = "Pre-intervention mean rating", y = "Post-intervention mean rating", title = "Change in polarization of topic-specific beliefs.", color = "Group") +
  scale_color_manual(values = c("control free reflection" = "darkseagreen", "selection bot" = "cornflowerblue", "combination bot" = "navyblue"), 
                     labels = c("control free reflection" = "Control group", "selection bot" = "Experimental group: Selection bot", "combination bot" = "Experimental group: Combination bot"))

print(polarization_scatterplot)

```

The offending reason t-test revealed a t-value of `r offending_reason_t_value` with a p-value of `r offending_reason_p_val`, indicating `r offending_reason_significance_status` between the change in experimental group subjects' severity of reasons that hold them back from conversing and control group subjects' change in severity (95% CI: `r offending_reason_ci`).

```{r}
#| label: fig-offending-reason-graph
#| echo: false
#| fig-cap: Scatterplot with line of equality of pre- and post-conversation mean ratings of reasons subjects might be unwilling to converse about their topic. Subjects rated how true the reasons were to them on a scale from 0 to 7, where a rating of 0 meant subject strongly disagreed and a rating of 7 meant strongly agree.

merged_offending_reason_df <- merge(pre_offending_reason_df, post_offending_reason_df, by = "prolific_subject_id")

offending_reason_scatterplot <- ggplot(merged_offending_reason_df, aes(x = pre_mean_score, y = post_mean_score, color = condition.x)) +
  geom_point() +  # Add points
  geom_abline(intercept = 0, slope = 1, color = "rosybrown1", linetype = "dashed") +  # Line of equality
  labs(x = "Pre-intervention mean rating", y = "Post-intervention mean rating", title = "Change in how much different concerns affect willingness to converse.", color = "Group") +
  scale_color_manual(values = c("control free reflection" = "darkseagreen", "selection bot" = "cornflowerblue", "combination bot" = "navyblue"), 
                     labels = c("control free reflection" = "Control group", "selection bot" = "Experimental group: Selection bot", "combination bot" = "Experimental group: Combination bot"))

print(offending_reason_scatterplot)

```

The sliders t-test revealed a t-value of `r sliders_t_value` with a p-value of `r sliders_p_val`, indicating `r sliders_significance_status` between the change in experimental group subjects' willingness to converse about their topic and control group subjects' change in willingness (95% CI: `r sliders_ci`).

```{r}
#| label: fig-sliders-graph
#| echo: false
#| fig-cap: Scatterplot with line of equality of pre- and post-conversation mean ratings of willingness to converse. Subjects rated their willingness on a slider from 0 to 100, where a rating of 0 meant subject was absolutely unwilling and a rating of 100 meant subject was absolutely willing.


merged_sliders_df <- merge(pre_sliders_df, post_sliders_df, by = "prolific_subject_id")

sliders_scatterplot <- ggplot(merged_sliders_df, aes(x = pre_mean_score, y = post_mean_score, color = condition.x)) +
  geom_point() +  # Add points
  geom_abline(intercept = 0, slope = 1, color = "rosybrown1", linetype = "dashed") +  # Line of equality
  labs(x = "Pre-intervention mean rating", y = "Post-intervention mean rating", title = "Change in willingness to converse about selected topic with others.", color = "Group") +
  scale_color_manual(values = c("control free reflection" = "darkseagreen", "selection bot" = "cornflowerblue", "combination bot" = "navyblue"), 
                     labels = c("control free reflection" = "Control group", "selection bot" = "Experimental group: Selection bot", "combination bot" = "Experimental group: Combination bot"))

print(sliders_scatterplot)

```

The open-mindedness t-test revealed a t-value of `r openmindedness_t_value` with a p-value of `r openmindedness_p_val`, indicating `r openmindedness_significance_status` between the change in experimental group subjects' open-mindedness on their topic and control group subjects' change in open-mindedness (95% CI: `r openmindedness_ci`).

```{r}
#| label: fig-openmindedness-graph
#| echo: false
#| fig-cap: Scatterplot with line of equality of pre- and post-conversation mean ratings of subjects' open-mindedness when discussing their topic. Subjects rated their open-mindedness on a scale from 0 to 7, where a rating of 0 meant subject was not open-minded and a rating of 7 meant subject was open-minded.

merged_openmindedness_df <- merge(pre_openmindedness_df, post_openmindedness_df, by = "prolific_subject_id")

openmindedness_scatterplot <- ggplot(merged_openmindedness_df, aes(x = pre_mean_score, y = post_mean_score, color = condition.x)) +
  geom_point() +  # Add points
  geom_abline(intercept = 0, slope = 1, color = "rosybrown1", linetype = "dashed") +  # Line of equality
  labs(x = "Pre-intervention mean rating", y = "Post-intervention mean rating", title = "Change in open-mindedness ratings before and after conversations.", color = "Group") +
  scale_color_manual(values = c("control free reflection" = "darkseagreen", "selection bot" = "cornflowerblue", "combination bot" = "navyblue"), 
                     labels = c("control free reflection" = "Control group", "selection bot" = "Experimental group: Selection bot", "combination bot" = "Experimental group: Combination bot"))

print(sliders_scatterplot)


```

### Example table of changes in average willingness to converse (slider questions)

```{r}
#| label: tbl-willingness-df
#| echo: false
#| tbl-cap: Table showing changes in willingness according to sliders. This is the same information as the willingness scatterplot.

example_table_of_changes <- surveys_df

example_table_of_changes <- example_table_of_changes %>%
  filter(grepl("slider", question)) %>%
  group_by(prolific_subject_id, phase) %>%
  summarize(condition = first(condition), 
            question = mean(as.numeric(answer), na.rm = TRUE), .groups = "drop") %>%
  #asked chat to give me code to separate into two columns
  mutate(
    'Post-conversation' = lead(question),   # Shift the 'questions' column up by one row
    row_number = row_number()       # Add a row number for filtering later
  ) %>%
  filter(row_number %% 2 == 1) %>%  # Keep only odd rows, where the new column now has even-row values
  select(question, 'Post-conversation', condition)        %>%
  rename("Pre-conversation"  = "question") %>%
  mutate_if(is.numeric, ~ round(., 1)) %>%
  arrange(desc(condition)) 

kable(example_table_of_changes)

  # mutate(across(everything(), ~ gsub('rating-republicans-post-', '', .))) %>%
  #   mutate(across(everything(), ~ gsub('rating-democrats-post-', '', .))) %>%
  # mutate(across(everything(), ~ gsub('pre-rating-republicans-', '', .))) %>%
  #   mutate(across(everything(), ~ gsub('pre-rating-democrats-', '', .))) 

# 
# part1_processing_example_table_of_changes <-processing_example_table_of_changes[1:6, ]
# part2_processing_example_table_of_changes <-processing_example_table_of_changes[7:12, ]
# 
# example_table_of_changes <- part1_processing_example_table_of_changes %>%
#   left_join(part2_processing_example_table_of_changes, by = "Subject's opinions on the opposite party", suffix = c("", "_new")) %>%
#     rename("Pre-Convo Ratings" = answer, "Post-Convo Ratings" =  answer_new) %>%
#   select("Subject's opinions on the opposite party", "Pre-Convo Ratings", "Post-Convo Ratings")
# 
# 
# print(example_table_of_changes)

```

### Three free reflections

```{r}
#| label: tbl-example-reflections
#| echo: false
#| tbl-cap: Example free reflections. Subjects received the statement that they rated most strongly in the pre-intervention survey. We prompted subjects to reflect for 10 minutes, and the timer paused if their keyboard inactivtiy exceeded 20 seconds. 

# make a simplified df to display reflections

example_reflections_df <- reflections_df %>%
  ungroup() %>%
  # only have three reflections right now, but will want to filter for just a few later on when we have more 
  # filter(prolific_subject_id == ) %>%
  select('Statement the subject reflected on', response, 'Time spent on reflection (minutes)')

kable(example_reflections_df)

```

```{r}
#| label: tbl-example-transcripts
#| include: false
#| tbl-cap: Example combo bot transcripts and selection bot transcripts with the bots' prompts

# make a simplified df with just a couple examples of conversations

example_conversation_transcripts <- conversations_df %>%
  filter(prolific_subject_id %in% c('5a7a1973000dab00018c3410', '60d6befca58e40d0c63bba9f')) %>%
  mutate(across(everything(), ~ gsub('time":.*', '', .))) %>%
  select(logs, condition)

#print(example_conversation_transcripts)

kable(example_conversation_transcripts, "html") %>%
  kable_styling() %>%
  column_spec(2, width = "20em") # Wrap text in the 2nd column, adjust width as needed

```

### Free response feedback from chatbot group subjects

```{r}
#| label: tbl-bot-feedback-df
#| echo: false
#| tbl-cap: Table showing subjects' responses to free response feedback questions. 

bot_feedback_figure <- bot_feedback %>%
  # turn each question into its own column so one subject can be one row
  pivot_wider(names_from = question, values_from = answer) %>%
  # for each subject, smash all the rows together into one
  group_by(prolific_subject_id) %>%
  reframe(across(everything(), ~ paste(unique(na.omit(.)), collapse = "; "))) %>%
  # unnecessary columns for visual display
  select(-c(prolific_subject_id, pilot_iteration.x, word_count)) %>%
  rename(
    Condition = condition,
    'Topic Choice' = 'topicChoiceAsString',
    'Did willingness increase?' = 'free-response',
    'Was conversation productive? Any parts affect willingness?' = 'convo-effect-on-willingness',
    'Any moments in convo open subject to new perspective?' = 'new-perspective',
    "What still contributes to willingness or unwillingness to converse?" = 'still-contributes',
    'Feedback on the bot?' = 'feelings-about-bot'
    )

kable(bot_feedback_figure, "html") %>%
  kable_styling() %>%
  column_spec(2, width = "5em") %>%
  column_spec(c(3,4,5,5), width = "40em")
```

```{r}
#| label: fig-topic-ratings
#| echo: false
#| fig-cap: In the pre-intervention survey, each subject used a 7-pt scale to rate how comfortable they would be discussing each of the following topics. One of the subject's most strongly rated topics were randomly selected as the topic that the subject would focus on for the remainder of the experiment. The scale went from strongly uncomfortable (1), to moderately uncomfortable, a little uncomfortable, neutral (4), a little comfortable, moderately comfortable, and strongly comfortable (7).

# create figure/table showing distribution of ratings on topics
topic_ratings_df <- surveys_df %>%
    filter(grepl("topic-", question)) %>%
  mutate(answer = as.numeric(answer)) %>%
  select(prolific_subject_id, question, answer, topicChoiceAsString, condition)
  
topic_labels <- c(
  "topic-mandating vaccines in the U.S." = 
    "Mandating vaccines",
  "topic-human euthanasia in the U.S." = 
    "Human euthanasia",
  "topic-the criminal justice system in the U.S." = 
    "Criminal justice system",
  "topic-same-sex marriage in the U.S." = 
    "Same-sex marriage",
  "topic-the role of the U.S. government in healthcare" = 
    "Government in healthcare",
  "topic-gender equality in the U.S." = 
    "Gender equality",
  "topic-the atomic bombings of Hiroshima and Nagasaki" = 
    "Atomic bombings"
)

topic_ratings_plot <- ggplot(topic_ratings_df, aes(x = answer, y = question, fill = question)) +
  geom_density_ridges() +
  # give the qualitative meanings of 1-7
  scale_x_continuous(breaks = seq(1, 7, by = 1)) +
   scale_y_discrete(labels = topic_labels) +
  # make it look nicer
  theme_ridges() +      
  # remove the legend
  theme(legend.position = "none") +
  labs(title = "Ridgeline Plot of Ratings by Topic",
       x = "Rating",
       y = "Contentious Topic")

print(topic_ratings_plot)
```

## Discussion

By conducting this research, we aimed to assess whether conversational LLMs can help Americans become more willing to have productive conversations about divisive topics. We found that \[summary\]

### Limitations

#### self-reported

#### situational vs. dispositional willingness

#### chatbot limitations 

https://journals.sagepub.com/doi/epub/10.1177/1532673X241263079

1. couldn't apply all human to human findings. for example, having people find similarities as people before talking about the issue @balietti2021

2. psychological safety / group-level intervention

reference our "Annotated Bibliography for Pilot A" Google Sheets doc for references about vulnerability, safety, and trust 

The literature clearly indicates that while individual skills like emotional regulation, communication competence, and conflict management are vital for engaging in difficult conversations, their effective application is deeply intertwined with the social environment. Thus, by not directly intervening on the systemic level, which includes aspects such as creating a psychologically safe environment, challenging negative norms, and promoting inclusivity, we are missing pieces of the puzzle that significantly influence individual willingness, especially “psychological safety.”

Psychological safety is the belief that one can speak openly and truthfully about problems without fear of reprisal; it is built upon three core pillars: care, consistency, and normalizing mistakes. Psychological safety is suggested to largely relate to group culture and norms in a conversation. Through developing greater abilities to navigate difficult conversations, users of our intervention may influence future group climates, which, in turn, could contribute to each member’s sense of psychological safety. This idea goes hand in hand with the finding that widespread individual avoidance can contribute to the formation of a silent, unsupportive opinion climate. However, the literature suggests that psychological safety is largely curated through systemic changes, especially for creating an environment where people from marginalized communities can experience the same sense of psychological safety as conventionally celebrated voices. Future research could explore applications of chatbots for systemic interventions.

reference @paluck2019 about racism and ethnicity 

Our primary goal, though, is to focus on the direct effects of individual interventions. By focusing solely on the individual level, perhaps users will grow in their abilities to navigate these difficult conversations even in spaces with poor group cultures or norms.


#### other measures  

[there were other key measures that the literature indicted were significant but that we didn't measure because we could only have so many measures and survey questions. reference @knochelmann2025 for intellectual humility ]

## Acknowledgements

We thank Dr. Steve Flusberg, Ian Ho, Victor Zhang, and Niranjan Baskaran for their crucial contributions to the experiment's webpage design, survey, and bots. We also thank Vassar College, as this study was made possible by funding from the college's Undergraduate Summer Research Insitute (URSI) program.

## References

## Appendix: Bot development

\[not sure if this is even necessary or do we only discuss the final product that we arrived at?\]

## Appendix: Prompts

*Counterargument bot prompt*:

Context/role: Your role is to be a policy education expert with whom people can discuss their beliefs about contentious topics. The user has previously indicated that the following concerns contribute to their unwillingness to discuss \[topic\] with others: "\[reasons for unwillingness\]." You are trying to help decrease the impact that these concerns have on the user's willingness without directly addressing these concerns.

Task: You should always concisely respond to the other person's argument with a counterargument. Do not repeat the same arguments that the 'role: assistant' has brought up before, but you can dive into more specific aspects or previous arguments. You should never dive into asking the user how they would implement their views. You should always concisely present a specific argument that counters the user's perspective. At the end of your response, you should always ask the user what they think.

Style: You should try to match the length of your response to the length of the most recent "role":"user":"content". You should never compliment or agree with the user's opinions, but you should still be conversational. You should focus instead on presenting alternative viewpoints and challenging assumptions with respect and technical precision, but do not be deferential.

*Question bot prompt*:

Context/role: Your role is to be a policy education expert with whom people can discuss their beliefs about contentious topics. The user has previously indicated that the following concerns contribute to their unwillingness to discuss \[topic\] with others: "\[reasons for unwillingness\]." You are trying to help decrease the impact that these concerns have on the user's willingness without directly addressing these concerns.

Task: You should concisely identify a specific group of people (e.g., people with different jobs, socioeconomic statuses, positions in society, beliefs) who may have differing opinions from the user. You should explain their experiences and why they may disagree with the user's beliefs. You should not repeat viewpoints that the 'role: assistant' brought up before, but you can dive deeper into previously mentioned viewpoints. You should always end your response with a question that asks the user what they think about those peoples' stances. You should provide only one viewpoint per response.

Style: You should try to match the length of your response to the length of the most recent "role":"user":"content". You should never compliment or agree with the user's opinions, but you should be conversational.

*Viewpoint bot prompt*:

Context/role: Your role is to be a policy education expert with whom people can discuss their beliefs about contentious topics. The user has previously indicated that the following concerns contribute to their unwillingness to discuss \[topic\]: "\[reasons for unwillingness\]." You are trying to help decrease the impact that these concerns have on the user's willingness without directly addressing these concerns.

Style: You should try to match the length of your response to the length of the most recent "role":"user":"content". You should never compliment or agree with the user's opinions, but you should still be conversational.

Task: You should always ask a question about the user's stance to help the user dig deeper into their own views. You should not repeat questions that the 'role: assistant' asked before, but you can expand upon previous questions.

*Selection bot prompt*:

Context/role: Your role is to be an unbiased conversational partner with whom people can discuss their beliefs about contentious topics. The user has previously indicated that the following concerns contribute to their unwillingness to discuss \[topic\] with others: "\[reasons for unwillingness\]." You are trying to help decrease the impact that these concerns have on the user's willingness without directly addressing these concerns.

Style: You should try to match the length of your response to the length of the most recent "role":"user":"content". You should never compliment or agree with the user's opinions, but you should still be conversational.

Task: Respond to the user however you see fit to help the user become more willing to discuss \[topic\] with others. Do not default to the most neutral or least confrontational response; you are allowed to challenge the user's views if you see fit.

Restrictions: You should keep the conversation on the topic of \[topic\]. You should not directly discuss the user's willingness concerns. You should ensure that your message prompts further discussion.

## Appendix: Sample transcripts

\[ do we want to insert some example transcripts here so that people can see them without having to go all the way to osf and parse the data?\]
